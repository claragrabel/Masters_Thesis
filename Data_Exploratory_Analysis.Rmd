---
title: "Data_Exploratory_Analysis"
author: "clagrabel"
date: "2024-06-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In this document, we will analyse RNAseq data (counts resulting from Salmon, aggregated at gene level using Tximport) using DESeq2. 
Data consists of 6 _Pelobates Cultripes_ populations (from 2 geographic regions), each population being subjected to benign conditions (constant high water level) and stressful conditions (low water level).


## Load the data

We load and store the data into a variable called txi.

```{r}
txi<-readRDS("salmon_gene_counts.rds")
```

We will load the libraries needed for this script.

```{r}
# use pacman to load libraries
pacman::p_load(DESeq2, tidyverse, fdrtool, UpSetR, GGally)
```


# Exploring the data

```{r, include=FALSE}
class(txi)
str(txi)
lapply(X=txi, FUN=head)
```

The txi object is a list with 4 entries, three matrices (abundance, counts, length) and 1 character vector (countsFromAbundance).

The dimensions of each matrix are 106236 rows as the genes and 48 columns as the sample_id. This means the transcripts have been aggregated into 106236 genes.


Here is a brief description of each element in the txi object: 
* Counts: Estimate of the number of reads mapping to each transcript.
* Abundance: Normalized counts in Transcripts Per Million (TPM). This means that per sample, the total counts add up to 1 million. Raw counts cannot be compared across sample_id because each library may vary slightly in terms of the total number of reads, differences in sequencing bias and difference in transcript lengths. 

```{r}
apply(X=txi$abundance, FUN=sum, MARGIN = 2)
```

* Length: Effective length of the target transcript.
* countsFromAbundance: A character vector indicating whether counts were taken directly from the quantifier (salmon) or whether they have been calculated from the abundances by tximport. Default is no (counts are from salmon).


Moreover, we can appreciate that the two first rows correspond to transcripts that mapped against mithocondrial RNA and non-coding RNA (nuclear ribosomal RNA) decoys introduced in the reference transcriptome. 

We will remove these.

_Regarding the non-coding RNA, we can see high counts in the counts matrix (without any normalization). Non-coding RNA molecules are abundant in the cell and are often not fully removed during RNA purification processes. All the transcripts were aggregated into one only "gene" or row called nrRNA, therefore showing a higher length  in the length matrix. Longer transcripts are expected to garner more reads simply because they provide more binding sites for the sequencing reads. Thus, in the abundance matrix their abundance is adjusted downward to account for their length._


# Filtering out mtRNA and nrRNA

We have to filter out the first two rows of every matrix. These two rows correspond to the mitochondrial RNA and nuclear ribosomal RNA that mapped against the decoys introduced in the reference transcriptome.

Moreover, there are genes named with the prefix "PECUL23nc" that are also non-coding, and non codinn RNA baits (nr baits). We have to find these genes and remove them. too.


```{r}

# Remove mtDNA, non-coding and nr baits

# make a list of genes we want to keep
whitelist<-txi$counts %>%
  as_tibble(rownames = "gene_id") %>%
  filter(!str_detect(gene_id, pattern = "mt|nr|nc")) %>%
  pull(gene_id)

length(whitelist);head(whitelist) # we are keeping 32531 genes

# filter txi tables
txi$abundance<-txi$abundance[whitelist,]
txi$counts<-txi$counts[whitelist,]
txi$length<-txi$length[whitelist,]
```


# Load design matrix

Load the design matrix for the dds object. 

```{r}

des.mat<-read_csv("./design_matrix.csv")

# Re-order factor levels
des.mat <- des.mat %>%
  mutate(population=factor(population, levels=c("Bui","Can","Tur","Esp","Jab","Lla"))) %>% # re-order factors for easy plotting later
  mutate(pop_n = factor(rep(rep(1:3,each=8),2))) %>% # The new variable pop_n created in the code does not depend on the levels of the population factor and is created independently by repeating a sequence. Hence, pop_n is non-nested with respect to population. 
  mutate_if(is.character, as.factor) # convert characters to factor

```


# Filtering out samples

We will filter samples that had substantially lower library size (Jab) and a potential outlier (Bui).

```{r}

des.mat<-des.mat %>%
  filter(!sample_id %in% c("Bui4H14_nonrrna","Jab5H6_nonrrna")) 

# filter txi tables
txi$abundance<-txi$abundance[,as.character(des.mat$sample_id)]
txi$counts<-txi$counts[,as.character(des.mat$sample_id)]
txi$length<-txi$length[,as.character(des.mat$sample_id)]

## get column order of counts matrix and re-order des.mat to match
col_order<-match(colnames(txi$counts),des.mat$sample_id)
des.mat<-des.mat[col_order,]
des.mat$sample_id==colnames(txi$counts)

des.mat
```



# Pre-filtering

The results function of the DESeq2 package that we will be using afterwards, performs its own independent filtering by default using the mean of normalized counts as a filter statistic. However, it might be worth applying a pre-filtering step with the aim of reducing the size of the matrix, speeding up downstream calculations and reducing memory requirements. This is also recommended in DESeq2 documentation.

```{r}

# Looking at the distribution without any filtering. Representing the sum of counts for each gene across all samples.

rowSums(counts(dds)) %>%
          enframe() %>%
  ggplot(aes(x=value)) +
  geom_histogram() +
  scale_x_log10()

# We will apply 2 different filters, a mild one and a strict one

dds1<-dds[rowSums(counts(dds) >= 1) >= 12,] # genes that have at least 1 count for 12 samples (e.g. one per treatment per population)
dim(dds1) # we are left with ~18k genes 

dds2<-dds[rowSums(counts(dds) >= 50) >= 12,] # genes that have at least 10 counts for 12 samples (e.g. one per treatment per population)
dim(dds2) # we are left with ~11k genes 
```



## Principal Component Analysis
 
Although the Differential Expression Analysis utilizes raw count data, for visualization or clustering, it makes more sense to use normalized data. DESeq authors argue that Variance Stabilized Transformation (VST) or regularized logarithm (rlog) have certain advantages. VST is faster, i.e. good for large datasets, rlog is more often used for small datasets. 

```{r}
# VST transformation
vst_dds<-vst(dds, blind = T) # no filtering
vst_dds1<-vst(dds1, blind = T) # mild filtering
vst_dds2<-vst(dds2, blind = T) # hard filtering

# Perform PCA on transposed scaled, centered data
vst_pca<- prcomp(t(assay(vst_dds)),  center = T)
vst_pca1<- prcomp(t(assay(vst_dds1)), center = T)
vst_pca2<- prcomp(t(assay(vst_dds2)), center = T)

```


### PCA emphasizing regions

```{r}
vst_pca$x %>%
  as_tibble(rownames = "sample_id") %>%
  left_join(des.mat) %>% # add the experimental design information
  ggpairs(columns = c("PC1", "PC2", "PC3", "PC4","PC5","PC6"), aes(color=region, shape=treatment)) +
  ggtitle("VST PCA (no filtering)")


vst_pca1$x %>%
  as_tibble(rownames = "sample_id") %>%
  left_join(des.mat) %>% # add the experimental design information
  ggpairs(columns = c("PC1", "PC2", "PC3", "PC4","PC5","PC6"),  aes(color=region, shape=treatment)) +
  ggtitle("VST PCA (mild liftering)")

vst_pca2$x %>%
  as_tibble(rownames = "sample_id") %>%
  left_join(des.mat) %>% # add the experimental design information
  ggpairs(columns = c("PC1", "PC2", "PC3", "PC4","PC5","PC6"),  aes(color=region, shape=treatment)) +
  ggtitle("VST PCA (hard liftering)")

```

 The diagonal displays the density distributions of a specific individual PC. The scatterplots show the pairwise relationships between different PCs, where each point represents a sample, colored by treatment and shaped by region. The X axis corresponds to the PC on the right and the Y axis corresponds to the PC on the top. Correlation coefficients quantify the linear relationship between the pair of PCs for each region. PC1 separates regions and PC3 separates treatments.

Filtering doesn't have a noticeable effect.

### PCA emphasizing treatment

```{r}
vst_pca1$x %>%
  as_tibble(rownames = "sample_id") %>%
  left_join(des.mat) %>% # add the experimental design information
  ggpairs(columns = c("PC1", "PC2", "PC3", "PC4","PC5","PC6"),  aes(color=treatment, shape=region)) +
  ggtitle("VST PCA")
```

Same PCA but colouring treatments instead of regions. It is not until susequent PCs that we get a treatment effect. PC1 vs PC3 may give us the best separation of both region and treatment.

Plot specific axes again to highlight some of this more clearly.

```{r}

# calculate hulls
pca_hull <- 
  vst_pca1$x %>% 
  as_tibble(rownames = "sample_id") %>%
  left_join(des.mat) %>%
  group_by(population, treatment) %>% 
  dplyr::slice(chull(PC1, PC3))

# plot PCA and facet into different populations
vst_pca1$x %>%
  as_tibble(rownames = "sample_id") %>%
  left_join(des.mat) %>% # add the experimental design information
  ggplot(aes(x=PC1, y=PC3, color=population, shape=treatment)) +
  geom_hline(yintercept = 0, linewidth=0.1) +
  geom_vline(xintercept = 0, linewidth=0.1) +
  geom_point(size=3) +
  geom_polygon(data = pca_hull,
               aes(fill = population,
                   colour = population,
                   linetype=treatment),
               alpha = 0.1,
               show.legend = FALSE) +
  ggrepel::geom_text_repel(aes(label=sample_id),size=2) +
  scale_color_manual(values=c("Bui"="#0FBA3D", "Can"="#0FBA93", "Tur"="#0F8CBA",
                              Esp="#900C3F", "Jab"="#FF5733", "Lla"="#FFC300"))+
  scale_fill_manual(values=c("Bui"="#0FBA3D", "Can"="#0FBA93", "Tur"="#0F8CBA",
                              Esp="#900C3F", "Jab"="#FF5733", "Lla"="#FFC300"))+
  facet_wrap(~population) +
  theme_minimal()

```


Warm colours (southern populations) are found on the left side of the plotting area and cold colours (central populations) on the right side. So PC1 is splitting regions quite well. the Y axis (PC3) on the other hand is fairly consistently splitting the triangles from the squares. 



